{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar-10-mlp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aerjayc/coe197z-hw1/blob/master/cifar_10_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VVHwkt0uORdR"
      },
      "source": [
        "First, we download the `CIFAR-10` dataset and extract its contents to the current directory. The working directory is now:\n",
        "\n",
        "\n",
        "```\n",
        ">ls\n",
        "  cifar-10-batches-py  cifar-10-python.tar.gz  sample_data\n",
        ">ls cifar-10-batches-py\n",
        "  batches.meta  data_batch_2  data_batch_4  readme.html\n",
        "  data_batch_1  data_batch_3  data_batch_5  test_batch\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBHS-YoKCpV8",
        "colab_type": "code",
        "outputId": "9189435d-88ef-49df-be78-3adda62ce638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "!tar -xzvf cifar-10-python.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-14 11:32:06--  http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  31.5MB/s    in 5.8s    \n",
            "\n",
            "2019-09-14 11:32:12 (28.1 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR8sSc0NZL3e",
        "colab_type": "text"
      },
      "source": [
        "Then, we \"unpickle\" the downloaded dataset. The `unpickle()` function was taken from the [CIFAR website](http://www.cs.toronto.edu/~kriz/cifar.html). It takes the filename of any of the batch files, and outputs the `dict` contained in that file.\n",
        "The structure of these `dict`'s is the following:\n",
        "\n",
        "\n",
        "```\n",
        "batch = {\n",
        "  b'batch_label': b'training batch 1 of 5',\n",
        "  b'data': array([ [<image_0>],\n",
        "                   ...,\n",
        "                   [<image 9999>]\n",
        "                 ], dtype=uint8),\n",
        "  b'filenames': [b'<filename_0.png',\n",
        "                 ...,\n",
        "                 b'<filename_9999.png',\n",
        "                ],\n",
        "  b'labels': [<label_0>, ..., <label_9999>],\n",
        "}\n",
        "```\n",
        "\n",
        "where:\n",
        "\n",
        "*   `[<image i>]` is a numpy vector of shape `(1024*1024*3,)`. The first `1024` entries in the vector correspond to the pixel intensities of the red channel, the second `1024` corresponds to the blue channel, and so on. Note that the pixel intensity spans the entire uint8 values.\n",
        "*   `b'<filename_i>'` is a binary string corresponding to the filename of the `i`-th image\n",
        "*   `<label_i>` $\\in \\{0,1,...,9\\}$, where each integer corresponds to some classification of the `i`-th image\n",
        "\n",
        "Note that the dictionary keys are binary strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOsCAN0uT7w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unpickle(file):\n",
        "  import pickle\n",
        "  with open(file, 'rb') as fo:\n",
        "    dict = pickle.load(fo, encoding='bytes')\n",
        "  return dict\n",
        "\n",
        "data_batch_1 = unpickle('cifar-10-batches-py/data_batch_1')\n",
        "test_batch   = unpickle('cifar-10-batches-py/test_batch')\n",
        "x1 = data_batch_1[b'data']\n",
        "y1 = data_batch_1[b'labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AiIG_tnM_6n",
        "colab_type": "text"
      },
      "source": [
        "https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9pOirjuBGHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def split_train_set(data, labels, data_fraction=0.8):\n",
        "  assert 0 < data_fraction <= 1\n",
        "\n",
        "  # jointly shuffle the data and labels first\n",
        "  # note: data and labels get shuffled (not copied)\n",
        "  rng_state = np.random.get_state()\n",
        "  np.random.shuffle(data)\n",
        "  np.random.set_state(rng_state)\n",
        "  np.random.shuffle(labels)\n",
        "\n",
        "  # get the first data_fraction of the train set\n",
        "  boundary = int(len(data)*data_fraction)\n",
        "  train_data   = data[:boundary]\n",
        "  train_labels = labels[:boundary]\n",
        "  validation_data = data[boundary:]\n",
        "  validation_labels = labels[boundary:]\n",
        "\n",
        "  return (train_data, train_labels), (validation_data, validation_labels)\n",
        "\n",
        "(x_train, y_train), (x_val, y_val) = split_train_set(x1, y1)\n",
        "\n",
        "# normalization, vectorization\n",
        "x_train = x_train.astype('float32') / 255\n",
        "y_train = to_categorical(y_train)\n",
        "x_val = x_val.astype('float32') / 255\n",
        "y_val = to_categorical(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETRxZJsWOYJa",
        "colab_type": "code",
        "outputId": "d1c13d61-674d-4316-9e7d-23a975455331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# input parameters\n",
        "input_shape = x_train[0].shape\n",
        "num_labels = 10\n",
        "\n",
        "# network parameters\n",
        "batch_size = 64\n",
        "hidden_units = 64\n",
        "data_augmentation = False\n",
        "epochs = 20\n",
        "max_batches = len(x_train) // batch_size\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(hidden_units, activation='relu', \n",
        "                       input_shape=input_shape))\n",
        "model.add(layers.Dense(hidden_units, activation='relu'))\n",
        "model.add(layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 64)                196672    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 201,482\n",
            "Trainable params: 201,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8kH2HKPjLRB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "52754d87-1698-447c-8952-30933ff3b85e"
      },
      "source": [
        "# training the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=epochs, batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/20\n",
            "8000/8000 [==============================] - 5s 669us/step - loss: 2.2446 - acc: 0.1855 - val_loss: 2.0226 - val_acc: 0.2340\n",
            "Epoch 2/20\n",
            "8000/8000 [==============================] - 1s 83us/step - loss: 2.0099 - acc: 0.2600 - val_loss: 1.9364 - val_acc: 0.2860\n",
            "Epoch 3/20\n",
            "8000/8000 [==============================] - 1s 82us/step - loss: 1.9263 - acc: 0.3061 - val_loss: 1.8925 - val_acc: 0.3045\n",
            "Epoch 4/20\n",
            "8000/8000 [==============================] - 1s 82us/step - loss: 1.8638 - acc: 0.3229 - val_loss: 1.8992 - val_acc: 0.3020\n",
            "Epoch 5/20\n",
            "8000/8000 [==============================] - 1s 78us/step - loss: 1.8243 - acc: 0.3421 - val_loss: 1.8667 - val_acc: 0.3070\n",
            "Epoch 6/20\n",
            "8000/8000 [==============================] - 1s 87us/step - loss: 1.7933 - acc: 0.3575 - val_loss: 1.8088 - val_acc: 0.3340\n",
            "Epoch 7/20\n",
            "8000/8000 [==============================] - 1s 81us/step - loss: 1.7651 - acc: 0.3627 - val_loss: 1.7993 - val_acc: 0.3315\n",
            "Epoch 8/20\n",
            "8000/8000 [==============================] - 1s 77us/step - loss: 1.7307 - acc: 0.3879 - val_loss: 1.7829 - val_acc: 0.3415\n",
            "Epoch 9/20\n",
            "8000/8000 [==============================] - 1s 84us/step - loss: 1.7142 - acc: 0.3837 - val_loss: 1.7873 - val_acc: 0.3455\n",
            "Epoch 10/20\n",
            "8000/8000 [==============================] - 1s 77us/step - loss: 1.6809 - acc: 0.4039 - val_loss: 1.7749 - val_acc: 0.3375\n",
            "Epoch 11/20\n",
            "8000/8000 [==============================] - 1s 81us/step - loss: 1.6685 - acc: 0.4057 - val_loss: 1.8347 - val_acc: 0.3395\n",
            "Epoch 12/20\n",
            "8000/8000 [==============================] - 1s 79us/step - loss: 1.6527 - acc: 0.4073 - val_loss: 1.8040 - val_acc: 0.3350\n",
            "Epoch 13/20\n",
            "8000/8000 [==============================] - 1s 78us/step - loss: 1.6286 - acc: 0.4233 - val_loss: 1.7517 - val_acc: 0.3640\n",
            "Epoch 14/20\n",
            "8000/8000 [==============================] - 1s 84us/step - loss: 1.6148 - acc: 0.4205 - val_loss: 1.7534 - val_acc: 0.3685\n",
            "Epoch 15/20\n",
            "8000/8000 [==============================] - 1s 83us/step - loss: 1.6059 - acc: 0.4243 - val_loss: 1.7911 - val_acc: 0.3600\n",
            "Epoch 16/20\n",
            "8000/8000 [==============================] - 1s 79us/step - loss: 1.5871 - acc: 0.4341 - val_loss: 1.7605 - val_acc: 0.3520\n",
            "Epoch 17/20\n",
            "8000/8000 [==============================] - 1s 86us/step - loss: 1.5731 - acc: 0.4360 - val_loss: 1.7936 - val_acc: 0.3745\n",
            "Epoch 18/20\n",
            "8000/8000 [==============================] - 1s 80us/step - loss: 1.5663 - acc: 0.4411 - val_loss: 1.8234 - val_acc: 0.3590\n",
            "Epoch 19/20\n",
            "8000/8000 [==============================] - 1s 81us/step - loss: 1.5543 - acc: 0.4483 - val_loss: 1.8992 - val_acc: 0.3480\n",
            "Epoch 20/20\n",
            "8000/8000 [==============================] - 1s 80us/step - loss: 1.5462 - acc: 0.4494 - val_loss: 1.7986 - val_acc: 0.3470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZKkWWm2hVBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting the training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(history):\n",
        "  # assert 'val_loss' in history.history\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epoch_axis = range(1, epochs + 1)\n",
        "\n",
        "  plt.plot(epoch_axis, loss, 'bo', label='Training loss')\n",
        "  plt.plot(epoch_axis, val_loss, 'b', label='Validation loss')\n",
        "\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZnwNbcDiw8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "05452abd-4cea-4292-c3d3-7dbbe2549efe"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUFERKKUFEREJOr/ATOqvoT9nJRKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4gCJvq5hdri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting the training and validation accuracy\n",
        "def plot_acc(history):\n",
        "  # assert 'val_acc' in history.history\n",
        "  acc = history.history['acc']\n",
        "  val_acc = history.history['val_acc']\n",
        "\n",
        "  plt.plot(epochs, acc, 'ro', label='Training acc')\n",
        "  plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "\n",
        "  plt.title('Training and validation loss & acc')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Acc')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}