{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar-10-mlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aerjayc/coe197z-hw1/blob/master/cifar_10_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fc9kcMI572i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape((-1,32*32*3))\n",
        "x_test = x_test.reshape((-1,32*32*3))\n",
        "\n",
        "# normalization, vectorization\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "x_train = x_train.astype('float32') / 255\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "x_test = x_test.astype('float32') / 255\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETRxZJsWOYJa",
        "colab_type": "code",
        "outputId": "f2af8a98-8584-466a-dcad-fdfee626c182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "\n",
        "# input parameters\n",
        "input_dim = 32*32*3\n",
        "num_labels = 10\n",
        "\n",
        "# network parameters\n",
        "batch_size = 512\n",
        "hidden_units = 1024\n",
        "epochs = 41\n",
        "\n",
        "dropout_rate = 0.3\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(hidden_units,\n",
        "                       activation='relu', \n",
        "                       input_dim=input_dim))\n",
        "model.add(layers.Dropout(dropout_rate))\n",
        "model.add(layers.Dense(hidden_units,\n",
        "                       activation='relu'))\n",
        "model.add(layers.Dropout(dropout_rate))\n",
        "model.add(layers.Dense(hidden_units,\n",
        "                       activation='relu'))\n",
        "model.add(layers.Dropout(dropout_rate))\n",
        "model.add(layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_81 (Dense)             (None, 1024)              3146752   \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 5,256,202\n",
            "Trainable params: 5,256,202\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8kH2HKPjLRB",
        "colab_type": "code",
        "outputId": "02d4ca45-748b-4fb4-b527-37389911e60c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/41\n",
            "50000/50000 [==============================] - 3s 58us/step - loss: 5.2594 - acc: 0.1488\n",
            "Epoch 2/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 2.0634 - acc: 0.2452\n",
            "Epoch 3/41\n",
            "50000/50000 [==============================] - 2s 37us/step - loss: 1.9767 - acc: 0.2819\n",
            "Epoch 4/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.9138 - acc: 0.3089\n",
            "Epoch 5/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.8660 - acc: 0.3276\n",
            "Epoch 6/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.8313 - acc: 0.3455\n",
            "Epoch 7/41\n",
            "50000/50000 [==============================] - 2s 37us/step - loss: 1.8031 - acc: 0.3519\n",
            "Epoch 8/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.7688 - acc: 0.3682\n",
            "Epoch 9/41\n",
            "50000/50000 [==============================] - 2s 37us/step - loss: 1.7482 - acc: 0.3753\n",
            "Epoch 10/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.7352 - acc: 0.3789\n",
            "Epoch 11/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.7101 - acc: 0.3877\n",
            "Epoch 12/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.6981 - acc: 0.3943\n",
            "Epoch 13/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.6765 - acc: 0.3983\n",
            "Epoch 14/41\n",
            "50000/50000 [==============================] - 2s 37us/step - loss: 1.6661 - acc: 0.4083\n",
            "Epoch 15/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.6560 - acc: 0.4109\n",
            "Epoch 16/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.6352 - acc: 0.4163\n",
            "Epoch 17/41\n",
            "50000/50000 [==============================] - 2s 37us/step - loss: 1.6264 - acc: 0.4196\n",
            "Epoch 18/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.6153 - acc: 0.4242\n",
            "Epoch 19/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.6117 - acc: 0.4269\n",
            "Epoch 20/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.6029 - acc: 0.4314\n",
            "Epoch 21/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5939 - acc: 0.4316\n",
            "Epoch 22/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5823 - acc: 0.4363\n",
            "Epoch 23/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5797 - acc: 0.4389\n",
            "Epoch 24/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5672 - acc: 0.4439\n",
            "Epoch 25/41\n",
            "50000/50000 [==============================] - 2s 37us/step - loss: 1.5640 - acc: 0.4423\n",
            "Epoch 26/41\n",
            "50000/50000 [==============================] - 2s 37us/step - loss: 1.5572 - acc: 0.4464\n",
            "Epoch 27/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5451 - acc: 0.4483\n",
            "Epoch 28/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5426 - acc: 0.4512\n",
            "Epoch 29/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5375 - acc: 0.4525\n",
            "Epoch 30/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5309 - acc: 0.4530\n",
            "Epoch 31/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5266 - acc: 0.4557\n",
            "Epoch 32/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5221 - acc: 0.4568\n",
            "Epoch 33/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5242 - acc: 0.4596\n",
            "Epoch 34/41\n",
            "50000/50000 [==============================] - 2s 37us/step - loss: 1.5089 - acc: 0.4631\n",
            "Epoch 35/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5061 - acc: 0.4648\n",
            "Epoch 36/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.5111 - acc: 0.4630\n",
            "Epoch 37/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.4964 - acc: 0.4680\n",
            "Epoch 38/41\n",
            "50000/50000 [==============================] - 2s 36us/step - loss: 1.4939 - acc: 0.4657\n",
            "Epoch 39/41\n",
            "50000/50000 [==============================] - 2s 37us/step - loss: 1.4944 - acc: 0.4680\n",
            "Epoch 40/41\n",
            "50000/50000 [==============================] - 2s 37us/step - loss: 1.4909 - acc: 0.4675\n",
            "Epoch 41/41\n",
            "50000/50000 [==============================] - 2s 37us/step - loss: 1.4899 - acc: 0.4689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRNMRWoNOdWi",
        "colab_type": "code",
        "outputId": "1c024b49-64e3-451e-b3b3-e8db3014f971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 120us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.488067834663391, 0.491]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    }
  ]
}