{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar-10-mlp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aerjayc/coe197z-hw1/blob/master/cifar_10_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VVHwkt0uORdR"
      },
      "source": [
        "First, we download the `CIFAR-10` dataset and extract its contents to the current directory. The working directory is now:\n",
        "\n",
        "\n",
        "```\n",
        ">ls\n",
        "  cifar-10-batches-py  cifar-10-python.tar.gz  sample_data\n",
        ">ls cifar-10-batches-py\n",
        "  batches.meta  data_batch_2  data_batch_4  readme.html\n",
        "  data_batch_1  data_batch_3  data_batch_5  test_batch\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBHS-YoKCpV8",
        "colab_type": "code",
        "outputId": "91efde2b-d11c-440c-e2a3-770bb7eb92f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "!tar -xzvf cifar-10-python.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-14 16:49:48--  http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  13.9MB/s    in 13s     \n",
            "\n",
            "2019-09-14 16:50:03 (12.1 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR8sSc0NZL3e",
        "colab_type": "text"
      },
      "source": [
        "Then, we \"unpickle\" the downloaded dataset. The `unpickle()` function was taken from the [CIFAR website](http://www.cs.toronto.edu/~kriz/cifar.html). It takes the filename of any of the batch files, and outputs the `dict` contained in that file.\n",
        "The structure of these `dict`'s is the following:\n",
        "\n",
        "\n",
        "```\n",
        "batch = {\n",
        "  b'batch_label': b'training batch 1 of 5',\n",
        "  b'data': array([ [<image_0>],\n",
        "                   ...,\n",
        "                   [<image 9999>]\n",
        "                 ], dtype=uint8),\n",
        "  b'filenames': [b'<filename_0.png',\n",
        "                 ...,\n",
        "                 b'<filename_9999.png',\n",
        "                ],\n",
        "  b'labels': [<label_0>, ..., <label_9999>],\n",
        "}\n",
        "```\n",
        "\n",
        "where:\n",
        "\n",
        "*   `[<image i>]` is a numpy vector of shape `(1024*1024*3,)`. The first `1024` entries in the vector correspond to the pixel intensities of the red channel, the second `1024` corresponds to the blue channel, and so on. Note that the pixel intensity spans the entire uint8 values.\n",
        "*   `b'<filename_i>'` is a binary string corresponding to the filename of the `i`-th image\n",
        "*   `<label_i>` $\\in \\{0,1,...,9\\}$, where each integer corresponds to some classification of the `i`-th image\n",
        "\n",
        "Note that the dictionary keys are binary strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOsCAN0uT7w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unpickle(file):\n",
        "  import pickle\n",
        "  with open(file, 'rb') as fo:\n",
        "    dict = pickle.load(fo, encoding='bytes')\n",
        "  return dict\n",
        "\n",
        "data_batch_1 = unpickle('cifar-10-batches-py/data_batch_1')\n",
        "data_batch_2 = unpickle('cifar-10-batches-py/data_batch_2')\n",
        "data_batch_3 = unpickle('cifar-10-batches-py/data_batch_3')\n",
        "data_batch_4 = unpickle('cifar-10-batches-py/data_batch_4')\n",
        "test_batch   = unpickle('cifar-10-batches-py/test_batch')\n",
        "# x1 = data_batch_1[b'data']\n",
        "# y1 = data_batch_1[b'labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYPDqOynsA16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.concatenate((data_batch_1[b'data'],\n",
        "              data_batch_2[b'data'],\n",
        "              data_batch_3[b'data'],\n",
        "              data_batch_4[b'data']))\n",
        "y = np.concatenate((data_batch_1[b'labels'],\n",
        "              data_batch_2[b'labels'],\n",
        "              data_batch_3[b'labels'],\n",
        "              data_batch_4[b'labels']))\n",
        "\n",
        "x_test = test_batch[b'data']\n",
        "y_test = test_batch[b'labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AiIG_tnM_6n",
        "colab_type": "text"
      },
      "source": [
        "https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9pOirjuBGHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_set(data, labels, data_fraction=0.8):\n",
        "  assert 0 < data_fraction <= 1\n",
        "\n",
        "  # jointly shuffle the data and labels first\n",
        "  # note: data and labels get shuffled (not copied)\n",
        "  rng_state = np.random.get_state()\n",
        "  np.random.shuffle(data)\n",
        "  np.random.set_state(rng_state)\n",
        "  np.random.shuffle(labels)\n",
        "\n",
        "  # get the first data_fraction of the train set\n",
        "  boundary = int(len(data)*data_fraction)\n",
        "  train_data   = data[:boundary]\n",
        "  train_labels = labels[:boundary]\n",
        "  validation_data = data[boundary:]\n",
        "  validation_labels = labels[boundary:]\n",
        "\n",
        "  return (train_data, train_labels), (validation_data, validation_labels)\n",
        "\n",
        "(x_train, y_train), (x_val, y_val) = split_train_set(x, y)\n",
        "\n",
        "# normalization, vectorization\n",
        "from keras.utils import to_categorical\n",
        "x_train = x_train.astype('float32') / 255\n",
        "y_train = to_categorical(y_train)\n",
        "x_val = x_val.astype('float32') / 255\n",
        "y_val = to_categorical(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETRxZJsWOYJa",
        "colab_type": "code",
        "outputId": "71a289a7-9c6d-4423-bc44-b3bf6cdb31e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# input parameters\n",
        "input_shape = x_train[0].shape\n",
        "num_labels = 10\n",
        "\n",
        "# network parameters\n",
        "batch_size = 64\n",
        "hidden_units = 128\n",
        "data_augmentation = False\n",
        "epochs = 50\n",
        "max_batches = len(x_train) // batch_size\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(hidden_units, activation='relu', \n",
        "                       input_shape=input_shape))\n",
        "model.add(layers.Dense(hidden_units, activation='relu'))\n",
        "model.add(layers.Dense(num_labels, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 128)               393344    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 411,146\n",
            "Trainable params: 411,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8kH2HKPjLRB",
        "colab_type": "code",
        "outputId": "89069b6f-8774-49d4-fdd5-731eb074f2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# training the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=epochs, batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/50\n",
            "32000/32000 [==============================] - 2s 70us/step - loss: 2.0468 - acc: 0.2654 - val_loss: 1.8892 - val_acc: 0.3294\n",
            "Epoch 2/50\n",
            "32000/32000 [==============================] - 2s 64us/step - loss: 1.8079 - acc: 0.3477 - val_loss: 1.7308 - val_acc: 0.3755\n",
            "Epoch 3/50\n",
            "32000/32000 [==============================] - 2s 64us/step - loss: 1.7256 - acc: 0.3822 - val_loss: 1.6864 - val_acc: 0.3960\n",
            "Epoch 4/50\n",
            "32000/32000 [==============================] - 2s 64us/step - loss: 1.6674 - acc: 0.4028 - val_loss: 1.6787 - val_acc: 0.3949\n",
            "Epoch 5/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.6297 - acc: 0.4168 - val_loss: 1.6457 - val_acc: 0.4093\n",
            "Epoch 6/50\n",
            "32000/32000 [==============================] - 2s 60us/step - loss: 1.5932 - acc: 0.4289 - val_loss: 1.6772 - val_acc: 0.3924\n",
            "Epoch 7/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.5658 - acc: 0.4413 - val_loss: 1.6406 - val_acc: 0.4276\n",
            "Epoch 8/50\n",
            "32000/32000 [==============================] - 2s 63us/step - loss: 1.5420 - acc: 0.4503 - val_loss: 1.6083 - val_acc: 0.4255\n",
            "Epoch 9/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.5179 - acc: 0.4602 - val_loss: 1.6753 - val_acc: 0.4153\n",
            "Epoch 10/50\n",
            "32000/32000 [==============================] - 2s 63us/step - loss: 1.5040 - acc: 0.4649 - val_loss: 1.5758 - val_acc: 0.4447\n",
            "Epoch 11/50\n",
            "32000/32000 [==============================] - 2s 60us/step - loss: 1.4853 - acc: 0.4687 - val_loss: 1.5581 - val_acc: 0.4512\n",
            "Epoch 12/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.4702 - acc: 0.4761 - val_loss: 1.6031 - val_acc: 0.4404\n",
            "Epoch 13/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.4565 - acc: 0.4818 - val_loss: 1.5375 - val_acc: 0.4587\n",
            "Epoch 14/50\n",
            "32000/32000 [==============================] - 2s 58us/step - loss: 1.4427 - acc: 0.4865 - val_loss: 1.6166 - val_acc: 0.4364\n",
            "Epoch 15/50\n",
            "32000/32000 [==============================] - 2s 58us/step - loss: 1.4243 - acc: 0.4911 - val_loss: 1.5828 - val_acc: 0.4569\n",
            "Epoch 16/50\n",
            "32000/32000 [==============================] - 2s 60us/step - loss: 1.4175 - acc: 0.4957 - val_loss: 1.5603 - val_acc: 0.4546\n",
            "Epoch 17/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.4069 - acc: 0.4997 - val_loss: 1.5481 - val_acc: 0.4657\n",
            "Epoch 18/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.3973 - acc: 0.5048 - val_loss: 1.5418 - val_acc: 0.4606\n",
            "Epoch 19/50\n",
            "32000/32000 [==============================] - 2s 60us/step - loss: 1.3881 - acc: 0.5048 - val_loss: 1.5592 - val_acc: 0.4582\n",
            "Epoch 20/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.3783 - acc: 0.5091 - val_loss: 1.5311 - val_acc: 0.4751\n",
            "Epoch 21/50\n",
            "32000/32000 [==============================] - 2s 60us/step - loss: 1.3683 - acc: 0.5127 - val_loss: 1.5917 - val_acc: 0.4469\n",
            "Epoch 22/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.3604 - acc: 0.5138 - val_loss: 1.5695 - val_acc: 0.4627\n",
            "Epoch 23/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.3515 - acc: 0.5161 - val_loss: 1.6483 - val_acc: 0.4380\n",
            "Epoch 24/50\n",
            "32000/32000 [==============================] - 2s 63us/step - loss: 1.3498 - acc: 0.5226 - val_loss: 1.5407 - val_acc: 0.4632\n",
            "Epoch 25/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.3411 - acc: 0.5195 - val_loss: 1.5591 - val_acc: 0.4629\n",
            "Epoch 26/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.3313 - acc: 0.5261 - val_loss: 1.5212 - val_acc: 0.4805\n",
            "Epoch 27/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.3236 - acc: 0.5280 - val_loss: 1.5480 - val_acc: 0.4664\n",
            "Epoch 28/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.3199 - acc: 0.5277 - val_loss: 1.5122 - val_acc: 0.4824\n",
            "Epoch 29/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.3159 - acc: 0.5327 - val_loss: 1.6086 - val_acc: 0.4600\n",
            "Epoch 30/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.3079 - acc: 0.5349 - val_loss: 1.5612 - val_acc: 0.4698\n",
            "Epoch 31/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.3034 - acc: 0.5330 - val_loss: 1.5352 - val_acc: 0.4785\n",
            "Epoch 32/50\n",
            "32000/32000 [==============================] - 2s 60us/step - loss: 1.2966 - acc: 0.5398 - val_loss: 1.5402 - val_acc: 0.4781\n",
            "Epoch 33/50\n",
            "32000/32000 [==============================] - 2s 59us/step - loss: 1.2921 - acc: 0.5387 - val_loss: 1.5549 - val_acc: 0.4800\n",
            "Epoch 34/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.2867 - acc: 0.5394 - val_loss: 1.5628 - val_acc: 0.4785\n",
            "Epoch 35/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.2843 - acc: 0.5411 - val_loss: 1.5723 - val_acc: 0.4705\n",
            "Epoch 36/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.2770 - acc: 0.5449 - val_loss: 1.5735 - val_acc: 0.4694\n",
            "Epoch 37/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.2762 - acc: 0.5452 - val_loss: 1.5642 - val_acc: 0.4740\n",
            "Epoch 38/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.2729 - acc: 0.5472 - val_loss: 1.5774 - val_acc: 0.4715\n",
            "Epoch 39/50\n",
            "32000/32000 [==============================] - 2s 60us/step - loss: 1.2686 - acc: 0.5496 - val_loss: 1.5809 - val_acc: 0.4776\n",
            "Epoch 40/50\n",
            "32000/32000 [==============================] - 2s 59us/step - loss: 1.2626 - acc: 0.5518 - val_loss: 1.5823 - val_acc: 0.4744\n",
            "Epoch 41/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.2610 - acc: 0.5501 - val_loss: 1.6080 - val_acc: 0.4749\n",
            "Epoch 42/50\n",
            "32000/32000 [==============================] - 2s 60us/step - loss: 1.2586 - acc: 0.5519 - val_loss: 1.5625 - val_acc: 0.4790\n",
            "Epoch 43/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.2544 - acc: 0.5527 - val_loss: 1.6377 - val_acc: 0.4600\n",
            "Epoch 44/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.2461 - acc: 0.5578 - val_loss: 1.6149 - val_acc: 0.4731\n",
            "Epoch 45/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.2457 - acc: 0.5539 - val_loss: 1.5660 - val_acc: 0.4833\n",
            "Epoch 46/50\n",
            "32000/32000 [==============================] - 2s 59us/step - loss: 1.2441 - acc: 0.5596 - val_loss: 1.6571 - val_acc: 0.4711\n",
            "Epoch 47/50\n",
            "32000/32000 [==============================] - 2s 61us/step - loss: 1.2427 - acc: 0.5573 - val_loss: 1.6337 - val_acc: 0.4681\n",
            "Epoch 48/50\n",
            "32000/32000 [==============================] - 2s 60us/step - loss: 1.2324 - acc: 0.5598 - val_loss: 1.6722 - val_acc: 0.4646\n",
            "Epoch 49/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.2292 - acc: 0.5617 - val_loss: 1.7141 - val_acc: 0.4425\n",
            "Epoch 50/50\n",
            "32000/32000 [==============================] - 2s 62us/step - loss: 1.2320 - acc: 0.5632 - val_loss: 1.6000 - val_acc: 0.4838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZnwNbcDiw8d",
        "colab_type": "code",
        "outputId": "4e7f1dd5-d802-4838-bcb0-7264694356bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZKkWWm2hVBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting the training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(history):\n",
        "  # assert 'val_loss' in history.history\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epoch_axis = range(1, epochs + 1)\n",
        "\n",
        "  plt.plot(epoch_axis, loss, 'bo', label='Training loss')\n",
        "  plt.plot(epoch_axis, val_loss, 'b', label='Validation loss')\n",
        "\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4gCJvq5hdri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting the training and validation accuracy\n",
        "def plot_acc(history):\n",
        "  # assert 'val_acc' in history.history\n",
        "  acc = history.history['acc']\n",
        "  val_acc = history.history['val_acc']\n",
        "\n",
        "  plt.plot(epochs, acc, 'ro', label='Training acc')\n",
        "  plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "\n",
        "  plt.title('Training and validation loss & acc')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Acc')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}